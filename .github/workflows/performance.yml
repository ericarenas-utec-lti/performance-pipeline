name: Automated Performance Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  performance:
    name: Performance Tests with JMeter
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Create directory structure
      run: |
        echo "ğŸ“ Creating project structure..."
        mkdir -p test-plans config results
        ls -la
        
    - name: Clean results directory
      run: |
        echo "ğŸ§¹ Cleaning previous results..."
        rm -rf results/*
        mkdir -p results
        
    - name: Convert PowerShell scripts to Unix format
      run: |
        echo "ğŸ”§ Converting scripts to Unix format..."
        # Convertir check-thresholds.sh si existe
        if [ -f "config/check-thresholds.sh" ]; then
          sed -i 's/\r$//' config/check-thresholds.sh
          chmod +x config/check-thresholds.sh
          echo "âœ… check-thresholds.sh converted"
        fi
        
    - name: Run JMeter performance tests
      run: |
        echo "ğŸš€ Running JMeter performance tests..."
        
        # Primero ejecutar sin reporte HTML para generar JTL
        docker run --rm \
          -v $PWD/test-plans:/test-plans \
          -v $PWD/results:/results \
          justb4/jmeter:5.5 \
          -n -t /test-plans/api-performance.jmx \
          -l /results/results.jtl \
          -Jthreads=3 \
          -Jrampup=10 \
          -Jduration=20
        
        echo "âœ… JMeter execution completed"
        
    - name: Generate HTML report from results
      run: |
        echo "ğŸ“Š Generating HTML report from results..."
        
        # Generar reporte HTML desde el JTL
        docker run --rm \
          -v $PWD/results:/results \
          justb4/jmeter:5.5 \
          -g /results/results.jtl \
          -o /results/html-report
        
        echo "âœ… HTML report generation completed"
        
    - name: Verify results were generated
      run: |
        echo "âœ… Checking generated files..."
        ls -la results/
        
        if [ -f "results/results.jtl" ]; then
          echo "ğŸ“ˆ Results file exists"
          # Mostrar primeras lÃ­neas para debug
          echo "=== First few lines of results ==="
          head -5 results/results.jtl
        else
          echo "âŒ No results file generated"
          exit 1
        fi
        
        if [ -d "results/html-report" ]; then
          echo "ğŸŒ HTML report directory exists"
          ls -la results/html-report/ | head -10
        else
          echo "âš ï¸ HTML report not generated"
        fi
        
    - name: Simple threshold verification
      run: |
        echo "ğŸ“Š Simple threshold verification..."
        
        if [ ! -f "results/results.jtl" ]; then
          echo "âŒ No results file"
          exit 1
        fi
        
        # VerificaciÃ³n bÃ¡sica - que el archivo tenga contenido
        FILE_SIZE=$(wc -c < "results/results.jtl")
        if [ "$FILE_SIZE" -lt 100 ]; then
          echo "âŒ Results file too small: $FILE_SIZE bytes"
          exit 1
        fi
        
        echo "âœ… Basic verification passed"
        echo "ğŸ“Š File size: $FILE_SIZE bytes"
        
        # Contar requests aproximados
        if head -1 results/results.jtl | grep -q "timeStamp"; then
          # Formato CSV
          REQUEST_COUNT=$(tail -n +2 results/results.jtl | wc -l)
          echo "ğŸ“ˆ Approx. requests: $REQUEST_COUNT"
        else
          # Formato XML
          REQUEST_COUNT=$(grep -c "<httpSample" results/results.jtl 2>/dev/null || echo "0")
          echo "ğŸ“ˆ Approx. requests: $REQUEST_COUNT"
        fi
          
    - name: Upload HTML Report Artifact
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: jmeter-html-dashboard
        path: results/html-report/
        retention-days: 30
        overwrite: true
        
    - name: Upload Test Results Artifact
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: jmeter-raw-results
        path: results/
        retention-days: 30
        overwrite: true
        
    - name: Display performance summary
      run: |
        echo "ğŸ“ˆ PERFORMANCE TEST SUMMARY"
        echo "============================"
        
        if [ -f "results/results.jtl" ]; then
          echo "âœ… Test execution: SUCCESS"
        else
          echo "âŒ Test execution: FAILED"
        fi
        
        if [ -d "results/html-report" ]; then
          echo "ğŸŒ HTML Dashboard: Generated"
        else
          echo "âš ï¸ HTML Dashboard: Not generated"
        fi
        
        echo ""
        echo "ğŸ“¦ Artifacts Available for Download:"
        echo "   - jmeter-html-dashboard: Interactive HTML report"
        echo "   - jmeter-raw-results: Raw test results"